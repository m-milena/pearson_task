{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEARSON RECRUITMENT TASK REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short description\n",
    "As data scientist, I had to investigate the university's admitance criteria and then build a system to predict students graduation probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Database\n",
    "   At the beginning I decided to create local SQL database to made data research easier. So I wrote [sql_students.sql](https://github.com/m-milena/pearson_task/blob/master/Database/sql_students.sql) script which initialize it, create two connected tables (**score_board** and **graduates**) and load data from csv files into them. Relation between tables was made by students id and it is 1:n, where n={0,1}.\n",
    "In the picture below there is the sql_students database model, which is available to download in [this](https://github.com/m-milena/pearson_task/tree/master/Database) folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/sql_db_model.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "After database creation, I was going to write some python scripts with queries to database. First of all I wrote database [configure file](https://github.com/m-milena/pearson_task/blob/master/Data_analysis/database_config.py) and functions to [connect](https://github.com/m-milena/pearson_task/blob/master/Data_analysis/database_connect.py) and [disconnect](https://github.com/m-milena/pearson_task/blob/master/Data_analysis/database_disconnect.py) database to made it universal to all .py files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database config file\n",
    "print(60*'-'+'\\nEnter username: ')\n",
    "db_user = input()\n",
    "print(60*'-'+'\\nEnter password: ')\n",
    "db_passwd = input()\n",
    "print(60*'-')\n",
    "\n",
    "db_connection_config = {\n",
    "\t'host':'127.0.0.1',\n",
    "\t'port':'3306',\n",
    "\t'database':'sql_students',\n",
    "\t'user':db_user,\n",
    "\t'passwd':db_passwd\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local database\n",
    "import mysql.connector\n",
    "\n",
    "def database_connect(db_connection_config):\n",
    "\n",
    "\ttry:\t\n",
    "\t\tdb_connection = mysql.connector.connect(**db_connection_config)\n",
    "\t\tif db_connection.is_connected():\n",
    "\t\t\tdb_info = db_connection.get_server_info()\n",
    "\t\t\tprint('Connected to MySQL database...\\nMySQL Server version on', db_info)\n",
    "\t\t\tdb_cursor = db_connection.cursor()\n",
    "\t\t\tdb_cursor.execute(\"select database();\")\n",
    "\t\t\tdb_record = db_cursor.fetchone()\n",
    "\t\t\tprint ('You are connected to', *db_record)\n",
    "\t\t\treturn db_connection\n",
    "\n",
    "\n",
    "\texcept mysql.connector.Error as db_error:\n",
    "\t\tprint ('Error while conecting to MySQL', db_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disconnect local database\n",
    "import mysql.connector\n",
    "\n",
    "def database_disconnect(db_connection, db_cursor):\n",
    "\tif(db_connection.is_connected()):\n",
    "\t\tdb_cursor.close()\n",
    "\t\tdb_connection.close()\n",
    "\t\tprint('MySQL connection is closed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I was going to investigate how many people recruit at university, how many is accepted and how many graduated. Using *mysql* python library I made query to sql_students database with years split (file: [students_quantity_analysis.py](https://github.com/m-milena/pearson_task/blob/master/Data_analysis/students_quantity_analysis.py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "from database_config import db_connection_config\n",
    "import database_connect\n",
    "import database_disconnect\n",
    "# database connect\n",
    "db_connection = database_connect.database_connect(db_connection_config)\n",
    "db_cursor = db_connection.cursor()\n",
    "\n",
    "# Get data about years of recruitment\n",
    "sql_select = \"SELECT DISTINCT year FROM score_board\"\n",
    "db_cursor.execute(sql_select)\n",
    "db_record = db_cursor.fetchall()\n",
    "years = []\n",
    "for row in db_record:\n",
    "\tyears.append(row[0]) \n",
    "\n",
    "\n",
    "# Get data about quantity of recruitment students in different years\n",
    "quantity_of_students= []\n",
    "for i in range(len(years)):\n",
    "\tsql_select = \"SELECT COUNT(id) FROM score_board WHERE year=\"+str(years[i])\n",
    "\tdb_cursor.execute(sql_select)\n",
    "\tdb_record = db_cursor.fetchall()\n",
    "\tquantity_of_students.append(*db_record[0])\n",
    "\n",
    "\n",
    "# Get data about how many students are accepted in different years\n",
    "quantity_of_accepted = []\n",
    "for i in range(len(years)):\n",
    "\tsql_select = \"SELECT COUNT(id) FROM score_board WHERE year=\"+str(years[i])+\" AND accepted='TRUE'\"\n",
    "\tdb_cursor.execute(sql_select)\n",
    "\tdb_record = db_cursor.fetchall()\n",
    "\tquantity_of_accepted.append(*db_record[0])\n",
    "\n",
    "\n",
    "# Get data about how many students graduated from different years\n",
    "quantity_of_graduated = []\n",
    "for i in range(len(years)):\n",
    "\tsql_select = \"SELECT COUNT(graduates.id) FROM graduates INNER JOIN score_board ON graduates.id=score_board.id WHERE score_board.year=\"+str(years[i])+\" AND graduated='TRUE'\"\n",
    "\tdb_cursor.execute(sql_select)\n",
    "\tdb_record = db_cursor.fetchall()\n",
    "\tquantity_of_graduated.append(*db_record[0])\n",
    "\n",
    "# Data graph\n",
    "import students_quantity_graph\n",
    "students_quantity_graph.draw_graph(years, quantity_of_students, quantity_of_accepted, quantity_of_graduated)\n",
    "\n",
    "\n",
    "# database disconnect\n",
    "database_disconnect.database_disconnect(db_connection, db_connection.cursor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also wanted to visualize this data, so I made a bar graph using [draw_graph()](https://github.com/m-milena/pearson_task/blob/master/Data_analysis/students_quantity_graph.py). Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import pandas as pd\n",
    "from graphs_stylesheet import color_palette\n",
    "from graphs_stylesheet import plot_settings, legend_settings\n",
    "def draw_graph(years, students, accepted, graduated):\n",
    "\t\n",
    "\t# graph config\n",
    "\tx_label = str(years)\n",
    "\tbar_width = 1\n",
    "\t\n",
    "\t# bars position\n",
    "\tx_position = []\n",
    "\tx_position2 = []\n",
    "\tx_position3 = []\n",
    "\tfor i in range(0,len(years)):\n",
    "\t\tx_position.append(1.1*i)\n",
    "\t\tx_position2.append(i*1.1-0.25)\n",
    "\t\tx_position3.append(i*1.1+0.25)\n",
    "\n",
    "\ttitle='Quantity of students in different years'\n",
    "\txlabel='YEARS'\n",
    "\tylabel='QUANTITY'\n",
    "\tplot_settings(plt, title, xlabel, ylabel)\n",
    "\n",
    "\tplt.bar(x_position, students, color=color_palette['light_grey'], edgecolor='white', width=bar_width, label='recruited')\n",
    "\tplt.bar(x_position2, accepted, color=color_palette['dark_grapefruit'], edgecolor='white', width=0.5, label='accepted')\n",
    "\tplt.bar(x_position3, graduated, color=color_palette['dark_basil'], edgecolor='white', width=0.5, label='graduated')\n",
    "\t\n",
    "\tax = plt.gca()\n",
    "\tcount = 0\n",
    "\tfor i in ax.patches:\n",
    "\t\tif count >= len(years):\n",
    "\t\t\tax.text(i.get_x()+0.05, i.get_height()+60, \\\n",
    "            \t\tstr(i.get_height()), fontsize=9,\n",
    "                \t\tcolor=color_palette['dark_dark_grey'], rotation=50, fontweight='heavy')\n",
    "\t\telse:\n",
    "\t\t\tax.text(i.get_x()+0.05, i.get_height()+20, \\\n",
    "            \t\tstr(i.get_height()), fontsize=9,\n",
    "                \t\tcolor=color_palette['dark_dark_grey'], fontweight='heavy')\n",
    "\t\tcount = count + 1\n",
    "\n",
    "\tlegend_settings(plt)\n",
    "\tplt.xticks(x_position, years, rotation=60, fontsize=12, color=color_palette['dark_dark_grey'])\n",
    "\tplt.yticks(np.arange(0, 2500, 250),fontsize=12, color=color_palette['dark_dark_grey'])\n",
    "\tplt.savefig(\"./Graphs/students_quantity_graph.png\",dpi=400)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To standardize graphs I created [file](https://github.com/m-milena/pearson_task/blob/master/Data_analysis/graphs_stylesheet.py) with my plots and subplots stylesheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color palette\n",
    "color_palette = {\n",
    "'light_ruby' : '#db3247', 'dark_ruby' : '#c02537',\n",
    "'light_grapefruit' : '#f05462', 'dark_grapefruit' : '#e04356',\n",
    "'light_bittersweet' : '#ff6d48', 'dark_bittersweet' : '#ec5536',\n",
    "'light_sunflower' : '#ffcc40', 'dark_sunflower' : '#fbba28',\n",
    "'light_straw' : '#ebce32', 'dark_straw' : '#dfc220',\n",
    "'light_grass' : '#9ed45c', 'dark_grass' : '#8cbf46',\n",
    "'light_basil' : '#19cb69', 'dark_basil' : '#19b95f',\n",
    "'light_mint' : '#3ecfe', 'dark_mint' : '#2abb9a',\n",
    "'light_teal' : '#9dcdcd', 'dark_teal' : '#7bb1b1',\n",
    "'light_aqua' : '#44c1ef', 'dark_aqua' : '#2baedc',\n",
    "'light_blue_jeans' : '#579df2', 'dark_blue_jeans' : '#448ae2',\n",
    "'light_lavender' : '#ac93ef', 'dark_lavender' : '#967be2',\n",
    "'light_plum' : '#8068bc', 'dark_plum' : '#6a51ac',\n",
    "'light_pink_rose' : '#ef87c2', 'dark_ink_rose' : '#d971b0',\n",
    "'light_beaver' : '#bca385', 'dark_beaver' : '#ab8e66',\n",
    "'light_chocolate' : '#8f8272', 'dark_chocolate' : '#7a7162',\n",
    "'light_light_grey' : '#f7f8fc', 'dark_light_grey' : '#e8e9ee',\n",
    "'light_grey' : '#cdd1da', 'dark_grey' : '#acb2c0',\n",
    "'light_dark_grey' : '#656b77', 'dark_dark_grey' : '#434957',\n",
    "'light_charcoal' : '#3d3c41', 'dark_charcoal' : '#323136'}\n",
    "\n",
    "# default plot settings\n",
    "def plot_settings(plt, title, xlabel, ylabel):\n",
    "\t\n",
    "\tfig = plt.gcf()\n",
    "\tfig.set_size_inches(20,10)\n",
    "\n",
    "\tax = plt.gca()\n",
    "\tax.set_facecolor('white')\n",
    "\tax.spines['top'].set_visible(False)\n",
    "\tax.spines['right'].set_visible(False)\n",
    "\tax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\tplt.setp(ax.spines.values(), color=color_palette['dark_dark_grey'])\n",
    "\n",
    "\tplt.xlabel(xlabel, fontsize=12, color=color_palette['dark_dark_grey'])\n",
    "\tplt.ylabel(ylabel, fontsize=12, color=color_palette['dark_dark_grey'])\n",
    "\tplt.title(title, fontweight=\"bold\", fontsize=20, color=color_palette['dark_dark_grey'])\n",
    "\n",
    "def legend_settings(plt):\n",
    "\tlegend = plt.legend(fontsize=12)\n",
    "\tplt.setp(legend.get_texts(), color=color_palette['dark_dark_grey'], alpha=0.8)\n",
    "\n",
    "\n",
    "def subplots_settings(plt, axarr, l_rows, l_columns, titles, xlabel, ylabel):\n",
    "\tfig = plt.gcf()\n",
    "\tfig.set_size_inches(12,8)\n",
    "\tcount = 0\n",
    "\tfor i in range(l_rows):\n",
    "\t\tfor j in range(l_columns):\n",
    "\t\t\taxarr[i,j].grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\t\t\taxarr[i,j].spines['top'].set_visible(False)\n",
    "\t\t\taxarr[i,j].spines['right'].set_visible(False)\n",
    "\t\t\tplt.setp(axarr[i,j].spines.values(), color=color_palette['dark_dark_grey'])\n",
    "\t\t\taxarr[i,j].set_title(titles[count], fontsize=14, color=color_palette['dark_dark_grey'])\n",
    "\t\t\taxarr[i,j].set_xlabel(xlabel[count], fontsize=12, color=color_palette['dark_dark_grey'])\n",
    "\t\t\taxarr[i,j].set_ylabel(ylabel[count], fontsize=12, color=color_palette['dark_dark_grey'])\n",
    "\t\t\tplt.setp(axarr[i,j].get_xticklabels(), fontsize=12, color=color_palette['dark_dark_grey'])\n",
    "\t\t\tplt.setp(axarr[i,j].get_yticklabels(), fontsize=12, color=color_palette['dark_dark_grey'])\n",
    "\t\t\tcount = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final result of the above scripts is presented in the picture below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Data_analysis/Graphs/students_quantity_graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, quantity of recruiters is very big and only a few of them are accepted. About 1/3 accepted students don't graduated, so Graduation Prediction System is necessary.\n",
    "\n",
    "Next, I analyzed scores range accepted people in different years (files: [score_points_analysis.py](https://github.com/m-milena/pearson_task/blob/master/Data_analysis/score_points_analysis.py), [score_points_graph](https://github.com/m-milena/pearson_task/blob/master/Data_analysis/score_points_graph.py)). I also got their average value of score.\n",
    "In the picture below there is a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Data_analysis/Graphs/score_points_graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is no rule about scores range, which students need to be accepted - there is no minimal score value. It all depends on students quantity and their score level.\n",
    "\n",
    "To build Graduation Prediction System I had to analyse exams results, scores and students activity (file: [graduated_score_analysis.py](https://github.com/m-milena/pearson_task/blob/master/Data_analysis/graduated_scores_analysis.py)). I splited this data on two groups: students who graduated and didn't. All results are available in [this](https://github.com/m-milena/pearson_task/tree/master/Data_analysis/Graphs/Scores_in_different_years) folder. As example result, there are graphs with data from 1990."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Data_analysis/Graphs/Scores_in_different_years/graduated_score_graph_1990_part1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Data_analysis/Graphs/Scores_in_different_years/graduated_score_graph_1990_part2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, results are ambiguous. There is no obvious rule, when student graduated or not. Of course, there people with higher maths exam result more often graduated and there are more students with higher score who graduated, so the score points aren't pointless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "\n",
    "My first step to designed neural network was inputs defintion. I decided to create 8 inputs with data:\n",
    "- GPA,\n",
    "- Maths exam,\n",
    "- Art exam,\n",
    "- Language exam,\n",
    "- Social activity,\n",
    "- Essay score,\n",
    "- Interview score,\n",
    "- Score.\n",
    "\n",
    "The network was going to return graduation probability in range 0-1 (where 0 - graduation impossible, 1 - graduation unquestionable).\n",
    "\n",
<<<<<<< HEAD
    "At the beginning, I prepared necessary data from sql database and save them to one csv file (to didn't waste time with connect to database while neural network architecture will be chosen)."
=======
    "At the beginning, I prepared necessary data from sql database and save them to one csv file (to didn't waste time with connect to database while neural network architecture will be choosen)."
>>>>>>> report
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "from database_config import db_connection_config\n",
    "import database_connect\n",
    "import database_disconnect\n",
    "import csv\n",
    "\n",
    "# database connect\n",
    "db_connection = database_connect.database_connect(db_connection_config)\n",
    "db_cursor = db_connection.cursor()\n",
    "\n",
    "sql_select = \"SELECT year, gpa, maths_exam, art_exam, language_exam, social_activity, essay_score, interview_score, score, graduated FROM sql_students.graduates INNER JOIN sql_students.score_board ON graduates.id=score_board.id\"\n",
    "\n",
    "with open('../Neural_network/neural_network_data.csv', 'w') as csvfile:\n",
    "\twriter = csv.writer(csvfile)\n",
    "\twriter.writerows([['year', 'gpa', 'maths exam', 'art exam', 'language exam', 'social activity', 'essay score', 'interview score', 'score', 'graduated']])\n",
    "\tdb_cursor.execute(sql_select)\n",
    "\tdb_record = db_cursor.fetchall()\n",
    "\tcount = 0\n",
    "\tfor row in db_record:\n",
    "\t\tif str(row[9]) =='TRUE':\n",
    "\t\t\tbinary_truefalse = 1\n",
    "\t\telif str(row[9]) == 'FALSE':\n",
    "\t\t\tbinary_truefalse = 0\n",
    "\t\telse:\n",
    "\t\t\tprint('ERROR: '+str(row[9])+' is wrong type')\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\twriter.writerow([row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], binary_truefalse])\n",
    "\n",
    "csvfile.close()\n",
    "\n",
    "# database disconnect\n",
    "database_disconnect.database_disconnect(db_connection, db_connection.cursor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After csv file creation, I loaded data to variables and convert them to input matrix and output array. Next I splited data to train, validate and test (respectively 70%, 15% and 15%). Then I implemented random neural network architecture and started modifying it, as long as I didn't achieve pretty good results. Chosen neural networks models were saved with their graphs and training history. \n",
    "\n",
    "Final neural network structure has 8 inputs, 3 hidden layers with ReLU activation function (16, 8 and 16 neurons) and output layer with 1 neuron and sigmoid activation function. Architecture was presented in the picture and python [script](https://github.com/m-milena/pearson_task/blob/master/Neural_network/neural_network_for_graduation_prediction.py) below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/nn_architecture.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('neural_network_data.csv')\n",
    "# Writing data to array\n",
    "dataset = df.values\n",
    "\n",
    "# Neural network inputs:\n",
    "X = dataset[:,1:9]\n",
    "# Neural network output\n",
    "Y = dataset[:,9]\n",
    "\n",
    "# Scaling X data to be from 0 to 1\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data to training and validation+test set (70/30%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size = 0.3)\n",
    "\n",
    "# Splitting data to validation and test set (50/50%)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size = 0.5)\n",
    "\n",
    "# Creating neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import advanced_activations\n",
    "\n",
    "# Adding Regularization to our Neural Network\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "# Network architecture\n",
    "model = Sequential([\n",
    "\tDense(16, kernel_initializer='normal', activation = 'relu', kernel_regularizer=regularizers.l2(0.02), input_shape = 8,)),\n",
    "\tDropout(0.5),\n",
    "\tDense(8, kernel_initializer='normal', activation = 'relu'),\n",
    "\tDense(16, kernel_initializer='normal', activation = 'relu'),\n",
    "\tDense(1, kernel_initializer='normal', activation = 'sigmoid'),\n",
    "])\n",
    "\n",
    "# Finding best weights\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# Training and validation\n",
    "hist = model.fit(X_train, Y_train, batch_size=30, epochs=80, validation_data = (X_val, Y_val))\n",
    "\n",
    "# Testing\n",
    "loss = model.evaluate(X_test, Y_test)[0]\n",
    "accuracy = model.evaluate(X_test, Y_test)[1]\n",
    "print(\"Test loss: \", loss)\n",
    "print(\"Test accuracy: \", accuracy)\n",
    "\n",
    "print('Do you want to save this model? y/n')\n",
    "answer = input()\n",
    "if answer == 'y':\n",
    "\tprint('Input filename:')\n",
    "\tfilename = input()\n",
    "\tmodel.save(filename+'.model')\n",
    "\thist_df = pd.DataFrame(hist.history) \n",
    "\twith open(filename+'_logg.csv', 'w') as f:\n",
    "    \t\thist_df.to_csv(f)\n",
    "\n",
    "# visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "if answer == 'y':\n",
    "\tplt.savefig(filename+'_loss_graph.png',dpi=400)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "if answer == 'y':\n",
    "\tplt.savefig(filename+'_acc_graph.png',dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loss was 0.61 and test accuracy 0.68. Training graphs are presented below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td><img src=\"../Neural_network/learned_networks/16x8x16_acc_t6835v7088_loss_graph.png\" width=\"500\"></td>\n",
    "<td><img src=\"../Neural_network/learned_networks/16x8x16_acc_t6835v7088_acc_graph.png\" width=\"500\"></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this system to predict graduation, I created simple interface connected to neural network. User have to write students data and after button click student graduation probability will be displayed. Interface was created in QtDesigner with PyQt (pictures below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td><img src=\"./Images/interface_window4.png\" width=\"500\"></td>\n",
    "<td><img src=\"./Images/interface_window3.png\" width=\"500\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./Images/interface_window1.png\" width=\"500\"></td>\n",
    "<td><img src=\"./Images/interface_window2.png\" width=\"500\"></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First two scripts ([run_NNinterface.py](https://github.com/m-milena/pearson_task/blob/master/Neural_network/Neural_network_interface/run_NNinterface.py), [NNinterface.py](https://github.com/m-milena/pearson_task/blob/master/Neural_network/Neural_network_interface/NNinterface.py)) below are responsible for interface usage. But third ([neural_network_prediction.py](https://github.com/m-milena/pearson_task/blob/master/Neural_network/Neural_network_interface/neural_network_prediction.py)) prepare and load data into neural network and return probability value to interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5 import QtWidgets, uic\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtWidgets import QMainWindow, QAction, QDialog, QApplication\n",
    "from NNinterface import NNinterface\n",
    "import sys\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    dlg = NNinterface()\n",
    "    dlg.show()\n",
    "    app.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neural_network_prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f3d30dd24ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPyQt5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtGui\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPyQt5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtWidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_network_prediction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNNinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQMainWindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neural_network_prediction'"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtWidgets, uic\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtWidgets import *\n",
    "from neural_network_prediction import check_probability\n",
    "\n",
    "class NNinterface(QMainWindow):\n",
    "\t\n",
    "\tgpa = 0\n",
    "\tmaths_exam = 0\n",
    "\tart_exam = 0\n",
    "\tlanguage_exam = 0\n",
    "\tessay_score = 0\n",
    "\tinterview_score = 0\n",
    "\tsocial_activity = 1\n",
    "\tscore = 0\n",
    "\tprobability = 0\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tuic.loadUi('graduation_prediction_interface.ui',self)\n",
    "\t\tself.setWindowTitle('Graduation prediction app')\n",
    "\t\tself.graduation.setVisible(False)\n",
    "\t\n",
    "\tdef on_graduation_button_clicked(self):\n",
    "\t\tself.graduation.setVisible(True)\n",
    "\t\tif self.gpa_edit.text() == \"\" or self.maths_edit.text() ==\"\" or self.art_edit.text() == \"\" or self.language_edit.text() == \"\" or self. essay_edit.text() == \"\" or self.interview_edit.text() == \"\" or self.score_edit.text() == \"\":\n",
    "\t\t\tself.graduation.setStyleSheet(\"\"\"QLineEdit {background-color: white}\"\"\")\n",
    "\t\t\tself.graduation.setText(\"!ERROR!\")\n",
    "\t\telse:\n",
    "\t\t\tgpa = float(self.gpa_edit.text())\n",
    "\t\t\tmaths_exam = float(self.maths_edit.text())\n",
    "\t\t\tart_exam = float(self.art_edit.text())\n",
    "\t\t\tlanguage_exam = float(self.language_edit.text())\n",
    "\t\t\tessay_score = float(self.essay_edit.text())\n",
    "\t\t\tinterview_score = float(self.interview_edit.text())\n",
    "\t\t\tscore = int(self.score_edit.text())\n",
    "\t\t\tsocial_activity = self.social_box.value()\n",
    "\t\t\n",
    "\t\t\tprobability = check_probability(gpa, maths_exam, art_exam, language_exam, social_activity, essay_score, interview_score, score)\n",
    "\t\t\tself.graduation.setText(str(round(probability, 2))+'%')\n",
    "\t\t\tif probability >= 70:\n",
    "\t\t\t\tself.graduation.setStyleSheet(\"\"\"QLineEdit {background-color: green}\"\"\")\n",
    "\t\t\telif probability >= 60:\n",
    "\t\t\t\tself.graduation.setStyleSheet(\"\"\"QLineEdit {background-color: yellow}\"\"\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.graduation.setStyleSheet(\"\"\"QLineEdit {background-color: red}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.models\n",
    "import numpy as np\n",
    "\n",
    "def check_probability(gpa, maths_exam, art_exam, language_exam, social_activity, essay_score, interview_score, score):\n",
    "\t\n",
    "\tdata =[[1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0], \n",
    "\t[gpa, maths_exam, art_exam, language_exam, social_activity, essay_score, interview_score, score],\n",
    "\t[4.0, 1.0, 1.0, 1.0, 5, 1.0, 1.0, 1115]]\n",
    "\n",
    "\tfrom sklearn import preprocessing\n",
    "\tmin_max_scaler = preprocessing.MinMaxScaler()\n",
    "\tdata_scale = min_max_scaler.fit_transform(data)\n",
    "\tdata_scaled =data_scale[1:2,:]\n",
    "\tmodel = keras.models.load_model(\"../learned_networks/16x8x16_acc_t6835v7088.model\")\n",
    "\n",
    "\tif (data_scaled.ndim == 1):\n",
    "\t    data_scaled = np.array([data_scaled])\n",
    "\n",
    "\tprediction = float(model.predict(data_scaled))\n",
    "\treturn prediction*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project organization\n",
    "To saved my project I used Git version control system (supported with Git Kraken) and also Github to publish my results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
